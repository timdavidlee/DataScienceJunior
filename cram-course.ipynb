{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Hour cram course\n",
    "\n",
    "Will use housing data. We will formulate and implement two different problems:\n",
    "\n",
    "1. Regression modeling on Sale Price\n",
    "2. Classification modeling on Housing Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-01 12:46:41--  https://s3.amazonaws.com/ink2019share/iowa_housing_train.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.136.238\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.136.238|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 460676 (450K) [text/csv]\n",
      "Saving to: ‘iowa_housing_train.csv’\n",
      "\n",
      "iowa_housing_train. 100%[===================>] 449.88K   331KB/s    in 1.4s    \n",
      "\n",
      "2019-05-01 12:46:42 (331 KB/s) - ‘iowa_housing_train.csv’ saved [460676/460676]\n",
      "\n",
      "--2019-05-01 12:46:42--  https://s3.amazonaws.com/ink2019share/iowa_housing_data_dict.txt\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.136.238\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.136.238|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13369 (13K) [text/plain]\n",
      "Saving to: ‘iowa_housing_data_dict.txt’\n",
      "\n",
      "iowa_housing_data_d 100%[===================>]  13.06K  21.4KB/s    in 0.6s    \n",
      "\n",
      "2019-05-01 12:46:43 (21.4 KB/s) - ‘iowa_housing_data_dict.txt’ saved [13369/13369]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/ink2019share/iowa_housing_train.csv\n",
    "!wget https://s3.amazonaws.com/ink2019share/iowa_housing_data_dict.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: review the data dictionary\n",
    "\n",
    "- Find fields that will be useless (does the house have pictures of serbian clowns?)\n",
    "- Find fields that are categorical (will need to be transformed)\n",
    "- Find fields that are numeric, but will probably have to be transformed to categories\n",
    "- note the units of the continous variable fields (will we have to transform the data)\n",
    "\n",
    "### Step 2: load the data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulldozer_Example.ipynb     auto-dataset.ipynb\n",
      "LICENSE                     auto-mpg-train.csv\n",
      "README.md                   crime_dataset.ipynb\n",
      "SuperConductorExample.ipynb iowa_housing_data_dict.txt\n",
      "Untitled.ipynb              iowa_housing_train.csv\n",
      "Untitled1.ipynb             word2vec_100d.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the CSV data\n",
    "housing_df = pd.read_csv(\"iowa_housing_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check the data for the following:\n",
    "\n",
    "- missing data (blanks)\n",
    "- outliers (a few points way too high, few points way too low)\n",
    "    - `.hist()` will be useful for this, will make histogram\n",
    "- imbalanced features ( 1000 x 0's and only 5 x 1's)\n",
    "- drop unnecessary rows\n",
    "- drop unnecessary columns\n",
    "- fill in the blanks with defaults if necessary\n",
    "- Any relationship that seems linear already?\n",
    "    - plot two variables against each other and see if relationship is linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: check for duplicate features\n",
    "\n",
    "An example of this is \"has garage\" and \"number of garage spaces\". This can be found by either the data dictionary or checking out the correlation matrix.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(dataframe.corr())\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "Look for fields with high correlation (close to 1) this are probably features that have a very close cousin that represents the same type of quantity. Keep only one of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Split the data into Continuous Features and Categorical Features\n",
    "\n",
    "- Make two data frames for continuous and categorical\n",
    "\n",
    "#### 5.1 for continuous\n",
    "\n",
    "- normalize (subtract the mean and divide by the std) the continous data\n",
    "\n",
    "#### 5.2 for categorical\n",
    "\n",
    "- look at the distribution of categories (per field) and consolidate if necessary\n",
    "- the convert to a collection of binary columns (keep track of your headings!)\n",
    "\n",
    "\n",
    "#### 5.3 glue the two dataframes back together\n",
    "\n",
    "- should use the `pd.concat` or `pd.merge` to accomplish this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step LINREG1: Split the data into TRAIN and TEST, X, Y\n",
    "\n",
    "We will save 20% of the data to score our algorithm. \n",
    "\n",
    "1. Randomly select 20 of the rows and save into a test dataframe\n",
    "2. split out the **sales price (Y)** of each of the datasets. The remaining features will be considered (X)\n",
    "3. you should have 4 different arrays, `X_train`, `X_test`, `y_train`, and `y_test` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step LINREG2: Create and fit a Linear Regression Model\n",
    "\n",
    "\n",
    "1. create a blank model\n",
    "2. fit it to the training data\n",
    "3. find the top features via the `model.coef_`\n",
    "4. show the top features, and calculate the MSE score between predictions and the actuals via the test set\n",
    "\n",
    "```python\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step LINREG3: Repeat and compare to LassoCV(cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step CLASSIFY1: Split the data into TRAIN and TEST, X, Y\n",
    "\n",
    "We will save 20% of the data to score our algorithm. \n",
    "\n",
    "1. Randomly select 20 of the rows and save into a test dataframe\n",
    "2. split out the **HouseStyle (Y)** of each of the datasets. The remaining features will be considered (X)\n",
    "3. you should have 4 different arrays, `X_train`, `X_test`, `y_train`, and `y_test` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step CLASSIFY2: Create and fit a Linear Regression Model\n",
    "\n",
    "\n",
    "1. create a blank model\n",
    "2. fit it to the training data\n",
    "3. find the top features via the `model.coef_`\n",
    "4. show the top features, and calculate the confusion matrix score between predictions and the actuals via the test set\n",
    "\n",
    "```python\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_proba = model.predict_prob(X_test)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step LINREG3: Repeat and compare to DecisionTreeClassifier(cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
